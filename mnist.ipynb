{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ngocanhdoan/MLM/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import gamspy as gp\n",
    "from gamspy.math.matrix import dim\n",
    "\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as ptl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform= ToTensor() )\n",
    "test_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform= ToTensor() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train' : DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'test' : DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x177f804c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3, padding=1) \n",
    "        self.fc1 = nn.Linear(10 * 28 * 28, 10)  \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Convolutional layer with ReLU activation\n",
    "        x = x.reshape(-1, 10 * 28 * 28)  # Flatten the tensor\n",
    "        x = self.fc1(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_index, (data,target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 20 == 0:\n",
    "            print(f'Train Epoch: (epoch) [{batch_index * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_index / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']: \n",
    "            data, target = data.to(device), target.to(device) \n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "\n",
    "    print(f\"\\nTest set: Average loss: {test_loss : .4f}, Accuracy {correct}/ {len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%\\)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: (epoch) [0/60000 (0%)]\t2.312140\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t1.404607\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.840585\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.637460\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.368846\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.508405\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.278641\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.350212\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.300526\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.220534\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.322537\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.249847\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.232082\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.310235\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.263862\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.280340\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.167914\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.178408\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.390677\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.222142\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.225383\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.173504\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.341064\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.264394\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.149722\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.251108\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.192954\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.192547\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.321842\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.131986\n",
      "\n",
      "Test set: Average loss:  0.0018, Accuracy 9473/ 10000 (95%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.173274\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.148871\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.065879\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.233220\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.115132\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.083733\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.079815\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.193859\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.165706\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.119985\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.127091\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.179228\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.172541\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.167370\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.152343\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.180536\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.145415\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.154982\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.155517\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.106061\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.106687\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.047124\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.175748\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.111929\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.089693\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.133621\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.092585\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.167500\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.097071\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.092787\n",
      "\n",
      "Test set: Average loss:  0.0013, Accuracy 9630/ 10000 (96%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.138207\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.137490\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.086520\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.154247\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.069304\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.067808\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.071771\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.096913\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.110981\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.166020\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.243784\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.234531\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.157297\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.075541\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.059167\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.066793\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.186160\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.070346\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.130547\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.136925\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.102673\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.072420\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.061072\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.119114\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.153879\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.049309\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.055835\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.093984\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.098724\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.057229\n",
      "\n",
      "Test set: Average loss:  0.0009, Accuracy 9712/ 10000 (97%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.148050\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.120151\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.109055\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.035159\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.037825\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.120610\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.064317\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.131805\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.052696\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.095138\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.083570\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.056851\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.040042\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.111114\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.028442\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.036500\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.019663\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.031381\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.116924\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.054543\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.066771\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.116689\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.052839\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.054797\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.024067\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.149799\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.049254\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.055561\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.099273\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.036704\n",
      "\n",
      "Test set: Average loss:  0.0008, Accuracy 9764/ 10000 (98%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.048180\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.048691\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.051837\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.032994\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.054078\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.135789\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.019536\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.064651\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.022047\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.042520\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.062265\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.123517\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.057139\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.018433\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.029623\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.100339\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.029945\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.033947\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.054192\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.075769\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.149916\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.140947\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.048726\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.044737\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.058171\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.044246\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.122367\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.022811\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.061616\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.029313\n",
      "\n",
      "Test set: Average loss:  0.0007, Accuracy 9768/ 10000 (98%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.080759\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.043462\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.069241\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.060475\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.040624\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.008882\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.032578\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.045405\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.042421\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.051346\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.009674\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.055033\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.043852\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.023310\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.014175\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.082840\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.060866\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.036703\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.092525\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.086900\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.032929\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.033653\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.025748\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.038508\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.035440\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.088837\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.178723\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.021871\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.059742\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.020754\n",
      "\n",
      "Test set: Average loss:  0.0007, Accuracy 9768/ 10000 (98%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.066122\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.016785\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.013259\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.013707\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.033574\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.007925\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.062141\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.017903\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.043942\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.054465\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.024684\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.032283\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.044410\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.027678\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.038770\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.018777\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.030789\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.016719\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.024229\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.072833\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.066456\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.072140\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.056316\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.043054\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.086560\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.068092\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.038618\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.052680\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.044268\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.054632\n",
      "\n",
      "Test set: Average loss:  0.0007, Accuracy 9787/ 10000 (98%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.028657\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.019678\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.018691\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.018693\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.067280\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.031447\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.029766\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.012799\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.037562\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.035213\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.038406\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.012467\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.068244\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.074749\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.022808\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.022284\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.026503\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.021338\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.041885\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.029200\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.022524\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.059464\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.022306\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.012976\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.027649\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.064939\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.010208\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.091678\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.019961\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.122223\n",
      "\n",
      "Test set: Average loss:  0.0007, Accuracy 9779/ 10000 (98%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.018081\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.024799\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.034480\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.066610\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.053848\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.016826\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.044116\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.026228\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.015422\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.010623\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.029915\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.038554\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.033263\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.019246\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.054124\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.014128\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.037356\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.020257\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.013676\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.014307\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.059372\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.034014\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.076446\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.040355\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.050034\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.026936\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.033426\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.079797\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.030641\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.068000\n",
      "\n",
      "Test set: Average loss:  0.0007, Accuracy 9787/ 10000 (98%\\)\n",
      "Train Epoch: (epoch) [0/60000 (0%)]\t0.027709\n",
      "Train Epoch: (epoch) [2000/60000 (3%)]\t0.037069\n",
      "Train Epoch: (epoch) [4000/60000 (7%)]\t0.007295\n",
      "Train Epoch: (epoch) [6000/60000 (10%)]\t0.081577\n",
      "Train Epoch: (epoch) [8000/60000 (13%)]\t0.026024\n",
      "Train Epoch: (epoch) [10000/60000 (17%)]\t0.114703\n",
      "Train Epoch: (epoch) [12000/60000 (20%)]\t0.008086\n",
      "Train Epoch: (epoch) [14000/60000 (23%)]\t0.016343\n",
      "Train Epoch: (epoch) [16000/60000 (27%)]\t0.008412\n",
      "Train Epoch: (epoch) [18000/60000 (30%)]\t0.007395\n",
      "Train Epoch: (epoch) [20000/60000 (33%)]\t0.056794\n",
      "Train Epoch: (epoch) [22000/60000 (37%)]\t0.010608\n",
      "Train Epoch: (epoch) [24000/60000 (40%)]\t0.026804\n",
      "Train Epoch: (epoch) [26000/60000 (43%)]\t0.013486\n",
      "Train Epoch: (epoch) [28000/60000 (47%)]\t0.024164\n",
      "Train Epoch: (epoch) [30000/60000 (50%)]\t0.012597\n",
      "Train Epoch: (epoch) [32000/60000 (53%)]\t0.022607\n",
      "Train Epoch: (epoch) [34000/60000 (57%)]\t0.061017\n",
      "Train Epoch: (epoch) [36000/60000 (60%)]\t0.009556\n",
      "Train Epoch: (epoch) [38000/60000 (63%)]\t0.013541\n",
      "Train Epoch: (epoch) [40000/60000 (67%)]\t0.017204\n",
      "Train Epoch: (epoch) [42000/60000 (70%)]\t0.041581\n",
      "Train Epoch: (epoch) [44000/60000 (73%)]\t0.023225\n",
      "Train Epoch: (epoch) [46000/60000 (77%)]\t0.045367\n",
      "Train Epoch: (epoch) [48000/60000 (80%)]\t0.068362\n",
      "Train Epoch: (epoch) [50000/60000 (83%)]\t0.027522\n",
      "Train Epoch: (epoch) [52000/60000 (87%)]\t0.023647\n",
      "Train Epoch: (epoch) [54000/60000 (90%)]\t0.052308\n",
      "Train Epoch: (epoch) [56000/60000 (93%)]\t0.127089\n",
      "Train Epoch: (epoch) [58000/60000 (97%)]\t0.019148\n",
      "\n",
      "Test set: Average loss:  0.0007, Accuracy 9791/ 10000 (98%\\)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.3081\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)   \u001b[39m# Replace with actual std value\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# Convert mean and std to GAMSPy parameters\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m mean_param \u001b[39m=\u001b[39m gp\u001b[39m.\u001b[39mParameter(m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, domain\u001b[39m=\u001b[39mdim(mean\u001b[39m.\u001b[39mshape), records\u001b[39m=\u001b[39mmean)\n\u001b[1;32m     32\u001b[0m std_param \u001b[39m=\u001b[39m gp\u001b[39m.\u001b[39mParameter(m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m\"\u001b[39m, domain\u001b[39m=\u001b[39mdim(std\u001b[39m.\u001b[39mshape), records\u001b[39m=\u001b[39mstd)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = MNIST(root='mnist_data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "for images, _ in train_loader:\n",
    "    batch_samples = images.size(0)  # Batch size (the last batch can have smaller size)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "\n",
    "mean /= len(train_loader.dataset)\n",
    "std /= len(train_loader.dataset)\n",
    "\n",
    "mean = mean.numpy()\n",
    "std = std.numpy()\n",
    "\n",
    "# Define mean and std values (assuming they have been calculated earlier)\n",
    "mean = np.array([0.1307], dtype=np.float32)  # Replace with actual mean value\n",
    "std = np.array([0.3081], dtype=np.float32)   # Replace with actual std value\n",
    "\n",
    "# Convert mean and std to GAMSPy parameters\n",
    "mean_param = gp.Parameter(m, name=\"mean\", domain=dim(mean.shape), records=mean)\n",
    "std_param = gp.Parameter(m, name=\"std\", domain=dim(std.shape), records=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gamspy.math.matrix import dim\n",
    "\n",
    "mean = (0.1307,)\n",
    "std = (0.3081,)\n",
    "\n",
    "# Get a single batch of data\n",
    "for data, target in loaders['test']:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    break\n",
    "\n",
    "batch = data.shape[0]\n",
    "\n",
    "# Reshape the input so it matches our declaration in GAMSPy\n",
    "data = data.reshape(batch, -1).T\n",
    "\n",
    "# Reshape the target, labels, so that we can provide them to GAMSPy\n",
    "target_df = pd.DataFrame(target.cpu())\n",
    "target_df[\"val\"] = 1\n",
    "target_df = target_df.pivot(columns=[0], values=\"val\").fillna(0).astype(bool)\n",
    "\n",
    "# Create a container\n",
    "m = gp.Container()\n",
    "\n",
    "# Set epsilon as you wish, higher it is, harder to solve\n",
    "diff_eps = 0.01\n",
    "\n",
    "# Extract weights from CNN model\n",
    "w_conv1_data = model.conv1.weight.cpu().detach().numpy().reshape(10, -1).T  # Flatten the conv layer weights\n",
    "w_fc1_data = model.fc1.weight.cpu().detach().numpy().T\n",
    "init_data = data.cpu().detach().numpy()\n",
    "\n",
    "# Define GAMSPy parameters\n",
    "w_conv1 = gp.Parameter(m, name=\"w_conv1\", domain=dim(w_conv1_data.shape), records=w_conv1_data)\n",
    "w_fc1 = gp.Parameter(m, name=\"w_fc1\", domain=dim(w_fc1_data.shape), records=w_fc1_data)\n",
    "init = gp.Parameter(m, name=\"inp\", domain=dim(init_data.shape), records=init_data)\n",
    "\n",
    "# Variables\n",
    "xn = gp.Variable(m, name=\"xn\", domain=dim((784, batch)))\n",
    "x1 = gp.Variable(m, name=\"x1\", domain=dim((784, batch)))\n",
    "x2 = gp.Variable(m, name=\"x2\", domain=dim((10 * 28 * 28, batch)))\n",
    "x3 = gp.Variable(m, name=\"x3\", domain=dim((10, batch)))\n",
    "a2 = gp.Variable(m, name=\"a2\", domain=dim((10 * 28 * 28, batch)))\n",
    "a3 = gp.Variable(m, name=\"a3\", domain=dim((10, batch)))\n",
    "\n",
    "sample_domain = xn.domain[1]\n",
    "digits_domain = a3.domain[0]\n",
    "\n",
    "target_set = gp.Set(m, name=\"targets\", domain=[sample_domain, digits_domain], records=target_df, uels_on_axes=True)\n",
    "\n",
    "# Assume we will get non-normalized input\n",
    "# This step is important because when we trained our neural network we normalized\n",
    "# with a mean and standard deviation, and here we need to do the same\n",
    "normalize_input = gp.Equation(m, name=\"transform_input\", domain=x1.domain)\n",
    "\n",
    "# Input to the neural network is noise + input image normalized\n",
    "normalize_input[...] = x1[...] == (xn[...] + init[...] - mean[0]) / std[0]\n",
    "\n",
    "# Noise has some limits since neural network was trained with the assumption\n",
    "# that the values are between 0-1 for the input\n",
    "xn.lo[...] = - init[...]\n",
    "xn.up[...] = - init[...] + 1 \n",
    "\n",
    "\n",
    "# Define convolution manually\n",
    "def manual_conv2d(x, w, b, output_shape):\n",
    "    out = np.zeros(output_shape)\n",
    "    batch_size, num_filters, height, width = output_shape\n",
    "    num_channels, kernel_height, kernel_width = w.shape[1:]\n",
    "    \n",
    "    for b_idx in range(batch_size):\n",
    "        for f_idx in range(num_filters):\n",
    "            for h in range(height):\n",
    "                for w in range(width):\n",
    "                    conv_sum = 0\n",
    "                    for c in range(num_channels):\n",
    "                        for kh in range(kernel_height):\n",
    "                            for kw in range(kernel_width):\n",
    "                                h_in = h + kh - kernel_height // 2\n",
    "                                w_in = w + kw - kernel_width // 2\n",
    "                                if 0 <= h_in < height and 0 <= w_in < width:\n",
    "                                    conv_sum += x[c, h_in, w_in, b_idx] * w[f_idx, c, kh, kw]\n",
    "                    out[b_idx, f_idx, h, w] = conv_sum + b[f_idx]\n",
    "    return out\n",
    "\n",
    "# Apply convolution manually\n",
    "conv_out_shape = (batch, 10, 28, 28)\n",
    "conv_out_data = manual_conv2d(x1.cpu().detach().numpy().reshape((1, 28, 28, batch)), \n",
    "                              w_conv1.cpu().detach().numpy().reshape((10, 1, 3, 3)), \n",
    "                              b_conv1.cpu().detach().numpy(), conv_out_shape)\n",
    "conv_out = gp.Parameter(m, name=\"conv_out\", domain=dim(conv_out_shape), records=conv_out_data.reshape(-1))\n",
    "\n",
    "# ReLU activation function\n",
    "calc_activation = gp.Equation(m, name=\"calc_activation\", domain=x2.domain)\n",
    "calc_activation[...] = a2[...] == gp.math.relu(conv_out.reshape(10 * 28 * 28, batch))\n",
    "\n",
    "# Fully connected layer operation\n",
    "calc_fc1 = gp.Equation(m, name=\"calc_fc1\", domain=[w_fc1.domain[1], x2.domain[1]])\n",
    "calc_fc1[...] = a3[...] == w_fc1.T @ a2[...] + b_fc1\n",
    "\n",
    "# Objective and constraints\n",
    "obj = gp.Variable(m, name=\"obj\", domain=[sample_domain])\n",
    "eq_so_far = m.getEquations()\n",
    "\n",
    "results = []\n",
    "result_z = []\n",
    "result_a = []\n",
    "\n",
    "# For every sample we need to solve another optimization problem\n",
    "# to find the minimal vector that changes the label\n",
    "for s in range(batch):\n",
    "    sample_target = int(target[s])\n",
    "    print(f\"sample {s + 1}/{batch}\")\n",
    "\n",
    "    # Ensure the correct label gets less probability than the incorrect labels\n",
    "    make_noise = gp.Equation(m, name=f\"false_label_{s}\", domain=[digits_domain])\n",
    "    make_noise[...] = a3[:, s] >= a3[sample_target, s] + diff_eps\n",
    "    \n",
    "    z = gp.Variable(m, name=\"z\")\n",
    "    specific_equations = [make_noise]\n",
    "\n",
    "    # Pick which norm you would like to use\n",
    "    norm = \"l2\"\n",
    "    if norm == \"l2\":\n",
    "        noise_magnitude = gp.Equation(m, name=f\"noise_magnitude_{s}\")\n",
    "        noise_magnitude[...] = z == gp.math.vector_norm(xn[:, s]) ** 2\n",
    "        specific_equations.append(noise_magnitude)\n",
    "    elif norm == \"linf\":\n",
    "        noise_magnitude_1 = gp.Equation(m, name=f\"noise_magnitude_1_{s}\", domain=xn.domain)\n",
    "        noise_magnitude_2 = gp.Equation(m, name=f\"noise_magnitude_2_{s}\", domain=xn.domain)\n",
    "        noise_magnitude_1[...] = z >= xn[:, s]\n",
    "        noise_magnitude_2[...] = z >= -xn[:, s]\n",
    "        specific_equations.append(noise_magnitude_1)\n",
    "        specific_equations.append(noise_magnitude_2)\n",
    "    \n",
    "    model_noise = gp.Model(\n",
    "        m,\n",
    "        name=\"noise\",\n",
    "        equations=[*eq_so_far, *specific_equations],\n",
    "        problem=\"NLP\",\n",
    "        sense=\"min\",\n",
    "        objective=z,\n",
    "    )\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    model_noise.solve(solver='CONOPT3') \n",
    "    res = xn.records.copy()\n",
    "\n",
    "    noise = np.array(res[res[f\"DenseDim{batch}_1\"] == str(s)].level).reshape(28, 28)\n",
    "    output = a3.records.copy()\n",
    "    \n",
    "    output = np.array(output[output[f\"DenseDim{batch}_1\"] == str(s)].level)\n",
    "    result_a.append(output)\n",
    "    results.append(noise)\n",
    "    result_z.append(z.records.copy().level[0])\n",
    "\n",
    "print(\"Adversarial examples generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
